{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VvS-2403/smart-obesity-predictor/blob/main/Ensemble_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sjY6WhX2fXsX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data processing: Replacing text labels with codes"
      ],
      "metadata": {
        "id": "WxPIPfrXV69v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding the bmi feature**"
      ],
      "metadata": {
        "id": "IFt5IpROXHdf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "collapsed": true,
        "id": "8Q_ZnInegFtK",
        "outputId": "7e24eb32-a316-4693-838d-092e9a3eedc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-6-2065361805.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[\"Gender\"] = df[\"Gender\"].replace({\"Male\": 0, \"Female\": 1})\n",
            "/tmp/ipython-input-6-2065361805.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[binary_cols] = df[binary_cols].replace({\"yes\": 1, \"no\": 0})\n",
            "/tmp/ipython-input-6-2065361805.py:28: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  X[columns_to_encode] = X[columns_to_encode].replace(mapping)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_encoded' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-6-2065361805.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mremaining_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns_to_scale\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcolumns_to_encode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_scaled_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_encoded' is not defined"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"dataset.csv\")\n",
        "df[\"Gender\"] = df[\"Gender\"].replace({\"Male\": 0, \"Female\": 1})\n",
        "binary_cols = [\"family_history_with_overweight\", \"FAVC\", \"SCC\", \"SMOKE\"]\n",
        "df[binary_cols] = df[binary_cols].replace({\"yes\": 1, \"no\": 0})\n",
        "df[\"BMI\"] = df[\"Weight\"] / (df[\"Height\"] ** 2)\n",
        "#id is irrelevant for classification\n",
        "X = df.drop([\"NObeyesdad\", \"id\"], axis=1)\n",
        "y = df[\"NObeyesdad\"]\n",
        "\n",
        "columns_to_scale = [\"BMI\",\"Height\",\"Weight\",\"CH2O\", \"FAF\", \"TUE\", \"FCVC\", \"NCP\", \"Age\"]\n",
        "columns_to_encode = [\"CAEC\", \"CALC\", \"MTRANS\"]\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X[columns_to_scale])\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=columns_to_scale)\n",
        "\n",
        "columns_to_encode = [\"CAEC\", \"CALC\", \"MTRANS\"]\n",
        "mapping = {\n",
        "    'no': 0,\n",
        "    'Sometimes': 1,\n",
        "    'Frequently': 2,\n",
        "    'Always': 3,\n",
        "    'Walking': 0,\n",
        "    'Public_Transportation': 1,\n",
        "    'Bike': 2,\n",
        "    'Motorbike': 3,\n",
        "    'Automobile': 4\n",
        "}\n",
        "\n",
        "X_encoded = X[columns_to_encode].replace(mapping)\n",
        "\n",
        "remaining_columns = X.drop(columns=columns_to_scale + columns_to_encode).reset_index(drop=True)\n",
        "\n",
        "X = pd.concat([X_scaled_df.reset_index(drop=True), X_encoded.reset_index(drop=True), remaining_columns], axis=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mapping of labels\n",
        "\n",
        "I observed that instead of the standard medical mapping, A random order where there is no linear relation gave better resultss for the minority class. Thus i went with the random order, a label encoder could also be used."
      ],
      "metadata": {
        "id": "NZJ-6XOd30ki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "medical_map = {\n",
        "    'Insufficient_Weight': 0,\n",
        "    'Normal_Weight': 1,\n",
        "    'Overweight_Level_I': 2,\n",
        "    'Overweight_Level_II': 3,\n",
        "    'Obesity_Type_I': 4,\n",
        "    'Obesity_Type_II': 5,\n",
        "    'Obesity_Type_III': 6\n",
        "}\n",
        "\n",
        "random_map = {\n",
        "    'Normal_Weight':0,\n",
        "    'Obesity_Type_II':1,\n",
        "    'Overweight_Level_II':2,\n",
        "    'Insufficient_Weight':3 ,\n",
        "    'Obesity_Type_I':4,\n",
        "    'Obesity_Type_III':5 ,\n",
        "    'Overweight_Level_I':6  # target class at 6\n",
        "}\n",
        "\n",
        "\n",
        "def get_f1_scores(label_map, label_name='Overweight_Level_I'):\n",
        "    y_encoded = y.map(label_map)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)\n",
        "\n",
        "    model = LGBMClassifier(random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    inv_map = {v: k for k, v in label_map.items()}\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    f1s = {inv_map[int(k)]: v['f1-score'] for k, v in report.items() if k.isdigit()}\n",
        "    return f1s\n",
        "\n",
        "\n",
        "f1_medical = get_f1_scores(medical_map)\n",
        "f1_random = get_f1_scores(random_map)\n",
        "\n",
        "print(\"F1 Scores with STANDARD Order:\")\n",
        "for cls in sorted(f1_medical):\n",
        "    print(f\"{cls:25}: {f1_medical[cls]:.4f}\")\n",
        "\n",
        "print(\"\\n F1 Scores with RANDOM Order:\")\n",
        "for cls in sorted(f1_random):\n",
        "    print(f\"{cls:25}: {f1_random[cls]:.4f}\")\n"
      ],
      "metadata": {
        "id": "gANQX0cRz-XY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_encoded = y.map(random_map)"
      ],
      "metadata": {
        "id": "n51QA-PU6eQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FEATURE SELECTION**\n",
        "\n",
        "Removing irrelevant features with the help of\n",
        "Feature importance graph with our so far best models\n",
        "\n",
        "Smoke  had almost no importance in the best three models,SCC also had very less importance, thus i decided to drop smoke and SCC\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rCS0YTzzav-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "importances = rf_model.feature_importances_\n",
        "\n",
        "\n",
        "feat_importances = pd.Series(importances, index=X_train.columns)\n",
        "\n",
        "\n",
        "feat_importances.sort_values().plot(kind='barh')\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.show()\n",
        "print(\"AFTER DROPPING SMOKE,SCC\")\n",
        "X_train=X_train.drop(['SMOKE','SCC'],axis=1)\n",
        "X_test=X_test.drop(['SMOKE','SCC'],axis=1)\n",
        "rf_model.fit(X_train,y_train)\n",
        "y_pred=rf_model.predict(X_test)\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "importances = rf_model.feature_importances_\n",
        "feat_importances = pd.Series(importances, index=X_train.columns)\n",
        "\n",
        "\n",
        "feat_importances.sort_values().plot(kind='barh')\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "os9rTpsnLVBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "Xg_model=XGBClassifier()\n",
        "Xg_model.fit(X_train,Y_train)\n",
        "y_pred=Xg_model.predict(X_test)\n",
        "print(classification_report(Y_test, y_pred))\n",
        "cm = confusion_matrix(Y_test, y_pred)\n",
        "print(cm)\n",
        "print(accuracy_score(Y_test, y_pred))\n",
        "importances = Xg_model.feature_importances_\n",
        "\n",
        "feat_importances = pd.Series(importances, index=X_train.columns)\n",
        "\n",
        "feat_importances.sort_values().plot(kind='barh')\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.show()\n",
        "print(\"AFTER DROPPING SMOKE\")\n",
        "X_train=X_train.drop(['SMOKE','SCC'],axis=1)\n",
        "X_test=X_test.drop(['SMOKE','SCC'],axis=1)\n",
        "Xg_model.fit(X_train,Y_train)\n",
        "y_pred=Xg_model.predict(X_test)\n",
        "print(accuracy_score(Y_test, y_pred))\n",
        "print(classification_report(Y_test, y_pred))\n",
        "importances = Xg_model.feature_importances_\n",
        "feat_importances = pd.Series(importances, index=X_train.columns)\n",
        "\n",
        "\n",
        "feat_importances.sort_values().plot(kind='barh')\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4aGgDT89kfDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "model = LGBMClassifier(max_depth=20)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(accuracy_score(Y_test, y_pred))\n",
        "importances = model.feature_importances_\n",
        "\n",
        "feat_importances = pd.Series(importances, index=X_train.columns)\n",
        "\n",
        "\n",
        "feat_importances.sort_values().plot(kind='barh')\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.show()\n",
        "print(\"AFTER DROPPING SMOKE,SCC\")\n",
        "X_train=X_train.drop(['SMOKE','SCC'],axis=1)\n",
        "X_test=X_test.drop(['SMOKE','SCC'],axis=1)\n",
        "model.fit(X_train,Y_train)\n",
        "y_pred=model.predict(X_test)\n",
        "print(accuracy_score(Y_test, y_pred))\n",
        "print(classification_report(Y_test, y_pred))\n",
        "importances = model.feature_importances_\n",
        "feat_importances = pd.Series(importances, index=X_train.columns)\n",
        "\n",
        "\n",
        "feat_importances.sort_values().plot(kind='barh')\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zCQEktnQn-qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=X.drop(['SMOKE','SCC'],axis=1)"
      ],
      "metadata": {
        "id": "lpFwrl7sAQfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic Multinomial regression model"
      ],
      "metadata": {
        "id": "DZZaekW-ozej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "lr_model = LogisticRegression(\n",
        "    multi_class='multinomial',\n",
        "    solver='lbfgs',\n",
        "    max_iter=1000,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = lr_model.predict(X_test)\n",
        "\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "QGkkxlub7Gyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "rf_model = RandomForestClassifier(\n",
        "    random_state=42,n_estimators=150,max_depth=15\n",
        ")\n",
        "#param_grid = {\n",
        "    #'n_estimators': [50, 100, 150],\n",
        "    #'max_depth': [5, 10, 15, None]\n",
        "#}\n",
        "#grid_search = GridSearchCV(\n",
        "    #estimator=rf_model,\n",
        "    #param_grid=param_grid,\n",
        "    #cv=3,\n",
        "    #scoring='f1_macro',\n",
        "\n",
        "\n",
        "#)\n",
        "\n",
        "# Fit on training data\n",
        "#grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and model\n",
        "#print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "we8JcLtZzITS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "#param_grid = {\n",
        "    #'n_estimators': [50, 100, 150],\n",
        "    #'max_depth': [5, 10, 15, None],\n",
        "    #'learning_rate': [0.01, 0.05, 0.1],\n",
        "    #'num_leaves':[5,10,15,20]\n",
        "#}\n",
        "#grid_search = GridSearchCV(\n",
        "    #estimator=rf_model,\n",
        "    #param_grid=param_grid,\n",
        "    #cv=3,\n",
        "    #scoring='f1_macro',\n",
        "\n",
        "\n",
        "#)\n",
        "\n",
        "# Fit on training data\n",
        "#grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and model\n",
        "#print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "lgbm=LGBMClassifier(learning_rate=0.1, max_depth=5,n_estimators=150,num_leaves=15,random_state=42)\n",
        "\n",
        "lgbm.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = lgbm.predict(X_test)\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "ORI3JYT87yFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "\n",
        "xgb_model = XGBClassifier(\n",
        "    objective='multi:softmax',\n",
        "    num_class=7,\n",
        "    use_label_encoder=False,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model_normal = LGBMClassifier(learning_rate=0.1, max_depth=3, n_estimators=150,random_state=42)\n",
        "#param_grid = {\n",
        "    #'n_estimators': [50, 100, 150],\n",
        "    #'learning_rate': [0.01, 0.05, 0.1],\n",
        "    #'max_depth': [3, 5, 7, 10],\n",
        "#}\n",
        "#grid_search = GridSearchCV(\n",
        "    #param_grid=param_grid,\n",
        "    #cv=3,\n",
        "   # scoring='f1_macro',\n",
        "\n",
        "\n",
        "#)\n",
        "\n",
        "\n",
        "#grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "#print(\"Best Parameters:\", grid_search.best_params_)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, ))"
      ],
      "metadata": {
        "id": "5Z9r8HcydJva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ensemble = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('lr',lr_model),\n",
        "        ('rf',rf_model),\n",
        "        ('xgb', xgb_model),\n",
        "        ('lgbm_n',lgbm)\n",
        "    ],\n",
        "    voting='soft',\n",
        "    weights=[0.2,1,1,1.5],  #  you can tune this\n",
        "\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "ensemble.fit(X_train, y_train)\n",
        "\n",
        "y_pred = ensemble.predict(X_test)\n",
        "\n",
        "print(\"Ensemble Accuracy: \", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "int_to_label = {v: k for k, v in random_map.items()}\n",
        "target_names = [int_to_label[i] for i in range(len(int_to_label))]\n",
        "\n",
        "print(\"\\nClassification Report:\\n\",\n",
        "      classification_report(y_test, y_pred, target_names=target_names))"
      ],
      "metadata": {
        "id": "64RXJNwc9ZuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogX_-ydJi6zN"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHQlf5toykDJKq3cZrtIWj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}